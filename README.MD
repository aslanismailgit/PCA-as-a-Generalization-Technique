I believe Principal Component Analysis is a powerful tool and data with different dimensions (weights in this case) reminds me the PCA.

This repo is a struggle to take a deep look into the weights by using PCA. 
How weights' characteristics change during the training?
Do we need that much of neurons?
Do we need all those "weights" necessary or a smaller dimension will be enough?
Can we change the architecture during the training?
Can we use PCA as generalization technique?

I am looking for answers those questions in this study, especially the very last one. 

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide1.jpg))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide2.jpg))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide3.jpg))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide4.jpg))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide5.jpg))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide6.jpg))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide7.jpg))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide8.jpg))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide9.jpg))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide10.jpg))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide11.jpg))
