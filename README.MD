I believe Principal Component Analysis is a powerful tool and data with different dimensions (weights in this case) reminds me the PCA.

This repo is a struggle to take a deep look into the weights by using PCA. 
How weights' characteristics change during the training?
Do we need that much of neurons?
Do we need all those "weights" necessary or a smaller dimension will be enough?
Can we change the architecture during the training?
Can we use PCA as generalization technique?

I am looking for answers those questions in this study, especially the very last one. 

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide1.png?raw=true))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide2.png?raw=true))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide3.png?raw=true))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide4.png?raw=true))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide5.png?raw=true))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide6.png?raw=true))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide7.png?raw=true))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide8.png?raw=true))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide9.png?raw=true))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide10.png?raw=true))

![alt text](https://github.com/aslanismailgit/PCA-as-a-Generalization-Teqhnique/blob/master/images/Slide11.png?raw=true))
